{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07c58b08",
   "metadata": {},
   "source": [
    "# Final Code: Machine Learning for Corporate Training Effectiveness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf61138",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load datasets\n",
    "employee_df = pd.read_csv('employee_data.csv')\n",
    "training_df = pd.read_csv('training_and_development_data.csv')\n",
    "engagement_df = pd.read_csv('employee_engagement_survey_data.csv')\n",
    "recruitment_df = pd.read_csv('recruitment_data.csv')\n",
    "\n",
    "# Merge datasets\n",
    "df = pd.merge(training_df, employee_df, left_on='Employee ID', right_on='EmpID', how='left')\n",
    "df = pd.merge(df, engagement_df, on='Employee ID', how='left')\n",
    "\n",
    "print(\"Final merged dataset shape:\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb8486a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing and feature engineering\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df['Training Date'] = pd.to_datetime(df['Training Date'], errors='coerce', dayfirst=True)\n",
    "df['Survey Date'] = pd.to_datetime(df['Survey Date'], errors='coerce', dayfirst=True)\n",
    "\n",
    "outcome_map = {'Failed': 0, 'Incomplete': 1, 'Completed': 2, 'Passed': 3}\n",
    "df['Training Outcome Score'] = df['Training Outcome'].map(outcome_map)\n",
    "\n",
    "for col in ['Engagement Score', 'Satisfaction Score', 'Work-Life Balance Score']:\n",
    "    df[col] = df[col].fillna(df[col].median())\n",
    "\n",
    "numeric_df = df.select_dtypes(include=['int64', 'float64'])\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(numeric_df.corr(), annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5)\n",
    "plt.title(\"Correlation Matrix of Numeric Features\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"correlation_heatmap.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77f18bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeling\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "df = df[df['Training Outcome Score'].notnull()]\n",
    "y = df['Training Outcome Score'].apply(lambda x: 1 if x >= 2 else 0)\n",
    "\n",
    "X = df[[\n",
    "    'Training Duration(Days)', 'Training Cost',\n",
    "    'Engagement Score', 'Satisfaction Score', 'Work-Life Balance Score',\n",
    "    'Current Employee Rating'\n",
    "]].fillna(0)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "def evaluate_model(name, y_test, y_pred):\n",
    "    return {\n",
    "        'Model': name,\n",
    "        'Accuracy': round(accuracy_score(y_test, y_pred), 3),\n",
    "        'Precision': round(precision_score(y_test, y_pred), 3),\n",
    "        'Recall': round(recall_score(y_test, y_pred), 3),\n",
    "        'F1 Score': round(f1_score(y_test, y_pred), 3)\n",
    "    }\n",
    "\n",
    "results = [\n",
    "    evaluate_model(\"Logistic Regression\", y_test, lr.predict(X_test)),\n",
    "    evaluate_model(\"Random Forest\", y_test, rf.predict(X_test)),\n",
    "    evaluate_model(\"XGBoost\", y_test, xgb.predict(X_test))\n",
    "]\n",
    "\n",
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6b7691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP analysis for interpretability\n",
    "import shap\n",
    "import numpy as np\n",
    "\n",
    "explainer = shap.TreeExplainer(rf)\n",
    "X_sample = X_test.sample(n=100, random_state=1)\n",
    "shap_vals = explainer.shap_values(X_sample)\n",
    "\n",
    "shap.summary_plot(shap_vals, X_sample, plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acda0ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean SHAP values and bar plot\n",
    "shap_vals_class1 = shap_vals[1]\n",
    "shap_mean = np.abs(shap_vals_class1).mean(axis=0)\n",
    "\n",
    "shap_df = pd.DataFrame({\n",
    "    'Feature': X_sample.columns,\n",
    "    'Mean |SHAP Value|': shap_mean\n",
    "}).sort_values(by='Mean |SHAP Value|', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=shap_df, x='Mean |SHAP Value|', y='Feature')\n",
    "plt.title(\"SHAP Feature Importance (Random Forest)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"shap_feature_importance.png\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
